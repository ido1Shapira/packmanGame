{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "map_dir = 'map 3'\n",
    "batch_file = 'data/'+map_dir+'/workers/Batch_4771377_batch_results.csv'\n",
    "\n",
    "path = 'data/'+map_dir+'/workers' # use your path\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "li = []\n",
    "li_new = []\n",
    "for filename in all_files:\n",
    "    fromOne = pd.read_csv(filename, index_col=None, header=0)\n",
    "    fromOne['filename'] = filename\n",
    "    if filename == batch_file:\n",
    "        li_new.append(fromOne)\n",
    "    else:\n",
    "        li.append(fromOne)\n",
    "\n",
    "workers = pd.concat(li, axis=0, ignore_index=True)\n",
    "new_workers = pd.concat(li_new, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### more then once at the last batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: HITId, dtype: int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = workers.groupby('WorkerId').count()\n",
    "df_new = new_workers.groupby('WorkerId').count()\n",
    "df_new[df_new['HITId'] > 1]['HITId']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the last batch against all batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WorkerId\n",
       "A2AY9FXPXCAC5F    1\n",
       "ARPBDM5QZ4XQC     1\n",
       "Name: HITId_left, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.join(df_new, on='WorkerId', how='inner', lsuffix='_left', rsuffix='_right')['HITId_left']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### more then once at all batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WorkerId\n",
       "A1HX7YHNYSZ8EK     6\n",
       "A1IKWVZZ26QTLU     2\n",
       "A1KEOGV7WQ0KVO     2\n",
       "A1RUBSQBBOJHPO     3\n",
       "A1TWVJS27CL3KT     3\n",
       "A2196PMIF2YORD     3\n",
       "A23DIRTLAL5RA6    12\n",
       "A23THJCA3UXKVB     2\n",
       "A2A7O6KYJ9GS8A     2\n",
       "A2AY9FXPXCAC5F     2\n",
       "A2FP41BSPG0Y4A     2\n",
       "A2JFL3H254VGZ7    10\n",
       "A2LPVNAJP8ZO0O    21\n",
       "A304UJAE051J89     2\n",
       "A3FMBSTZ3ZGSV1    16\n",
       "A3HVFSD8K94SOR     2\n",
       "A3IOOW5SX3UDSG     4\n",
       "A3LTGXX5HIYDBM     6\n",
       "A3TL58QRW3A2NS     4\n",
       "A3V0ZNHKABDUMM     3\n",
       "ALLQYIBNGN5MG      4\n",
       "AM6MFRG64A2EX      2\n",
       "ARPBDM5QZ4XQC      2\n",
       "Name: HITId, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_workers = pd.concat([workers, new_workers], axis=0, ignore_index=True)\n",
    "all = all_workers.groupby('WorkerId').count()\n",
    "all[all['HITId'] > 1]['HITId']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 ('tf-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad60775ae12af945b53c5c94c294ef05f229143b8585a0d23625a81e181fdccc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
