{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import json\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "path = './data/packman-game-default-rtdb-export.json'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# import pyrebase\n",
    "\n",
    "# firebaseConfig = {\n",
    "#         \"apiKey\": \"AIzaSyAy6TmnVcLWjkpSpQFtCnX-PVGignQFsiw\",\n",
    "#     \"authDomain\": \"packman-game.firebaseapp.com\",\n",
    "#     \"databaseURL\": \"https://packman-game-default-rtdb.firebaseio.com\",\n",
    "#     \"projectId\": \"packman-game\",\n",
    "#     \"storageBucket\": \"packman-game.appspot.com\",\n",
    "#     \"messagingSenderId\": \"819894936980\",\n",
    "#     \"appId\": \"1:819894936980:web:7cbb8a8e4efb4e00d81b81\"\n",
    "#     };\n",
    "\n",
    "# firebase=pyrebase.initialize_app(firebaseConfig)\n",
    "\n",
    "# db=firebase.database()\n",
    "\n",
    "# # Get a database reference to our posts\n",
    "# ref = db.reference('/all-games')\n",
    "\n",
    "# # Read the data at the posts reference (this is a blocking operation)\n",
    "# print(ref.get())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#load data from the json file\r\n",
    "with open(path) as train_file:\r\n",
    "    data = json.load(train_file)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Survay results:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "upload Id workers and search for duplicate workers\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "participants_df = pd.DataFrame.from_dict(data['all-games'], orient='index')\r\n",
    "\r\n",
    "path = 'data/workers' # use your path\r\n",
    "all_files = glob.glob(path + \"/*.csv\")\r\n",
    "\r\n",
    "li = []\r\n",
    "\r\n",
    "for filename in all_files:\r\n",
    "    fromOne = pd.read_csv(filename, index_col=None, header=0)\r\n",
    "    fromOne['filename'] = filename\r\n",
    "    li.append(fromOne)\r\n",
    "\r\n",
    "workers = pd.concat(li, axis=0, ignore_index=True)\r\n",
    "workers = workers.set_index('Answer.surveycode')\r\n",
    "workers.index = workers.index.map(lambda code: '-' + code[:-3])\r\n",
    "participants_df['WorkerId'] = workers['WorkerId']\r\n",
    "participants_df.head(5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "try:\r\n",
    "    pd.concat(g for _, g in participants_df.groupby('WorkerId') if len(g) > 1).groupby('WorkerId')['index'].count()\r\n",
    "except ValueError:\r\n",
    "    pass"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "participants_df.columns"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "how many to drop?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "try:\r\n",
    "    sum(pd.concat(g for _, g in participants_df.groupby('WorkerId') if len(g) > 1).groupby('WorkerId')['index'].count()) - len(pd.concat(g for _, g in participants_df.groupby('WorkerId') if len(g) > 1).groupby('WorkerId')['index'].count())\r\n",
    "except ValueError:\r\n",
    "    pass\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will keep the first one of any 'WorkerId' instance to keep samples unique"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "participants_df = participants_df[(~participants_df.duplicated('WorkerId')) | (participants_df['WorkerId'].isnull())]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "number of people that answer the survay:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "len(participants_df)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "participants_df['additional_comments'][participants_df['additional_comments'].notna()][participants_df['additional_comments'] != \"\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "participants_df.groupby('behavior').mean()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "participants_df['gender'].value_counts()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "participants_df['education'].value_counts()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# View some data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "raw_df_state_to_action = pd.DataFrame.from_dict(data['humanModel'], orient='index')\r\n",
    "# df.reset_index(level=0, inplace=True)\r\n",
    "# df = df.dropna(subset=['log'])\r\n",
    "raw_df_state_to_action = raw_df_state_to_action.drop(0, axis=1)\r\n",
    "raw_df_state_to_action.info(verbose=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class DisplayState:\n",
    "    def __init__(self, state):\n",
    "        self.size = len(state)\n",
    "        self.h = self.size\n",
    "        self.w = self.size\n",
    "        self.raw_state = state\n",
    "        self.board = np.array(state[0]).astype(np.float)\n",
    "        self.human_trace = np.array(state[1]).astype(np.float)\n",
    "        self.computer_trace = np.array(state[2]).astype(np.float)\n",
    "        self.human_awards = np.array(state[3]).astype(np.float)\n",
    "        self.computer_awards = np.array(state[4]).astype(np.float)\n",
    "        self.all_awards = np.array(state[5]).astype(np.float)\n",
    "        self.dict = {\n",
    "                    \"Board\": self.board,\n",
    "                    \"Human trace\": self.human_trace,\n",
    "                    \"Computer trace\": self.computer_trace,\n",
    "                    \"Human awards\": self.human_awards,\n",
    "                    \"Computer awards\": self.computer_awards,\n",
    "                    \"All awards\": self.all_awards,\n",
    "                    }\n",
    "    def ToGrayScale(self, which='all'):\n",
    "        if(which == 'all'):\n",
    "            axes=[]\n",
    "            fig=plt.figure(figsize=(10,8))\n",
    "            i=0\n",
    "            j=0\n",
    "            for key in self.dict:\n",
    "                axes.append(fig.add_subplot(2, 3, i+1))\n",
    "                i=i+1\n",
    "                subplot_title=(\"Subplot: \"+str(key))\n",
    "                axes[-1].set_title(subplot_title)  \n",
    "                plt.imshow(self.dict[key])\n",
    "            fig.tight_layout()    \n",
    "        else:\n",
    "            plt.imshow(self.dict[which], interpolation='nearest')\n",
    "        plt.show()\n",
    "    def NormalizeData(self, data):\n",
    "        return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
    "\n",
    "    def ToImage(self):\n",
    "        try:\n",
    "            i_a_h, j_a_h = np.where(self.human_awards == 1) #indexes of the human_awards\n",
    "        except:\n",
    "            print(\"An exception occurred at: human_awards\")    \n",
    "        try:\n",
    "            i_a_c, j_a_c = np.where(self.computer_awards == 1) #indexes of the computer_awards\n",
    "        except:\n",
    "            print(\"An exception occurred at: computer_awards\")\n",
    "        \n",
    "        r = self.board/10 + self.all_awards\n",
    "        r += self.human_trace\n",
    "        \n",
    "        if(not np.any(self.all_awards)):\n",
    "            g = np.zeros([10,10])\n",
    "        else:    \n",
    "            g = self.board + self.all_awards*3\n",
    "        \n",
    "        b = self.board/10 + self.all_awards/10\n",
    "        b += self.computer_trace\n",
    "        \n",
    "        if i_a_h.size != 0:\n",
    "            r[i_a_h, j_a_h] += 0.5\n",
    "            g[i_a_h, j_a_h] += 0.2\n",
    "            b[i_a_h, j_a_h] += 0.2\n",
    "        if i_a_c.size != 0:\n",
    "            r[i_a_c, j_a_c] += 0.2\n",
    "            g[i_a_c, j_a_c] += 0.2\n",
    "            b[i_a_c, j_a_c] += 0.5\n",
    "        \n",
    "        r = self.NormalizeData(r)\n",
    "        g = self.NormalizeData(g)\n",
    "        b = self.NormalizeData(b)\n",
    "\n",
    "        rgb = np.dstack((r,g,b))\n",
    "        return rgb"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# def extractState(cell):\r\n",
    "#     if cell != None:\r\n",
    "#         ds = DisplayState(cell['state'])\r\n",
    "#         return ds.ToImage()\r\n",
    "#     return np.nan\r\n",
    "\r\n",
    "def extractAction(cell):\r\n",
    "    if cell != None:\r\n",
    "        return int(cell['action'])\r\n",
    "    return np.nan\r\n",
    "\r\n",
    "def NormalizeData(data):\r\n",
    "    return (data - np.min(data)) / (np.max(data) - np.min(data))\r\n",
    "\r\n",
    "def extractState(cell):\r\n",
    "    if cell == None:\r\n",
    "        return cell\r\n",
    "    board = np.array(cell['state'][0]).astype(float)\r\n",
    "    human_trace = np.array(cell['state'][1]).astype(float)\r\n",
    "    computer_trace = np.array(cell['state'][2]).astype(float)\r\n",
    "    human_awards = np.array(cell['state'][3]).astype(float)\r\n",
    "    computer_awards = np.array(cell['state'][4]).astype(float)\r\n",
    "    all_awards = np.array(cell['state'][5]).astype(float)\r\n",
    "    \r\n",
    "    r = human_awards/2 + human_trace + all_awards\r\n",
    "    g = board/3 + all_awards\r\n",
    "    b = computer_awards/2 + computer_trace + all_awards\r\n",
    "    rgb = np.dstack((r,g,b))\r\n",
    "    return NormalizeData(rgb)\r\n",
    "    \r\n",
    "\r\n",
    "state_df = pd.DataFrame(columns=raw_df_state_to_action.columns)\r\n",
    "action_df = pd.DataFrame(columns=raw_df_state_to_action.columns)\r\n",
    "for col in raw_df_state_to_action:\r\n",
    "    state_df[col] = raw_df_state_to_action[col].apply(extractState)\r\n",
    "    action_df[col] = raw_df_state_to_action[col].apply(extractAction)"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "state_df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "action_df[len(action_df.columns) + 1] = np.NaN\r\n",
    "action_df.tail()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Make Dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "counter = 0\r\n",
    "for (idxRow, s1), (_, s2) in zip(state_df.iterrows(), action_df.iterrows()):\r\n",
    "    for (idxCol, state), (_, action) in zip(s1.iteritems(), s2.iteritems()):\r\n",
    "        # check if it is not the last state\r\n",
    "        # the last state not enter our model, since it is an end state that not contains any dirts\r\n",
    "        if not np.isnan(action_df.loc[idxRow, idxCol+1]):\r\n",
    "            im = Image.fromarray((state * 255).astype(np.uint8))\r\n",
    "            path = f'data/humanModel/imagesDatabase/{int(action)}/{idxRow}_{idxCol}.png'\r\n",
    "            if counter % 100 == 0:\r\n",
    "                # print every 100 saved images\r\n",
    "                print(f'{idxRow}_{idxCol}.png saved! at action {action}')\r\n",
    "            counter += 1\r\n",
    "            im.save(path)\r\n",
    "        else:\r\n",
    "            break\r\n",
    "#         print (state, action, idxCol, idxRow)\r\n",
    "print(f'{counter} images have been saved')"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "index = \"-MhzLUHSR7dKkVbu38H0\"\r\n",
    "col = 3\r\n",
    "plt.imshow(state_df.loc[index, col])\r\n",
    "title = \"id: \" + index + \", col: \" + str(col) + \", action: \" + str(action_df.loc[index, col])\r\n",
    "plt.title(title)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit ('tf-gpu': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "interpreter": {
   "hash": "1082b87752d344a6f2b48e40943af295ff3001e9caeb2502a6ba4c36176c89b5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}