{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pyimagesearch.com/2018/06/04/keras-multiple-outputs-and-multiple-losses/\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "# ! pip install split-folders\n",
    "from imutils import paths\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "# from tensorflow.keras.preprocessing import image\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rs = 42\n",
    "def reset_random_seeds(rs):\n",
    "   os.environ['PYTHONHASHSEED']=str(rs)\n",
    "   tf.random.set_seed(rs)\n",
    "   np.random.seed(rs)\n",
    "   random.seed(rs)\n",
    "reset_random_seeds(rs)\n",
    "\n",
    "map_dir = 'map 5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into train , test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_list = ['collaborative_value','computer_value','predictable_value','selfishly_value','wisely_value']\n",
    "rate_vectors = pd.read_csv('./data/humanModel_v1_dataset/target.csv', names=header_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collaborative_value</th>\n",
       "      <th>computer_value</th>\n",
       "      <th>predictable_value</th>\n",
       "      <th>selfishly_value</th>\n",
       "      <th>wisely_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5589</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5590</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5591</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5592</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5593</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5594 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      collaborative_value  computer_value  predictable_value  selfishly_value  \\\n",
       "0                       5               6                  5                5   \n",
       "1                       5               6                  5                5   \n",
       "2                       5               6                  5                5   \n",
       "3                       5               6                  5                5   \n",
       "4                       5               6                  5                5   \n",
       "...                   ...             ...                ...              ...   \n",
       "5589                    7               4                  7                1   \n",
       "5590                    7               4                  7                1   \n",
       "5591                    7               4                  7                1   \n",
       "5592                    7               4                  7                1   \n",
       "5593                    7               4                  7                1   \n",
       "\n",
       "      wisely_value  \n",
       "0                4  \n",
       "1                4  \n",
       "2                4  \n",
       "3                4  \n",
       "4                4  \n",
       "...            ...  \n",
       "5589             4  \n",
       "5590             4  \n",
       "5591             4  \n",
       "5592             4  \n",
       "5593             4  \n",
       "\n",
       "[5594 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n"
     ]
    }
   ],
   "source": [
    "# grab the image paths and randomly shuffle them\n",
    "print(\"[INFO] loading images...\")\n",
    "# imagePaths = sorted(list(paths.list_images('./data/humanModel_v1_dataset/')))\n",
    "# random.shuffle(imagePaths)\n",
    "imagePaths = list(paths.list_images('./data/humanModel_v1_dataset/'))\n",
    "\n",
    "# initialize the data\n",
    "data = []\n",
    "actionLabels = []\n",
    "rate_vector_value = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "IMG_SIZE = 10\n",
    "\n",
    "# loop over the input images\n",
    "for imagePath in imagePaths:\n",
    "\t# load the image, pre-process it, and store it in the data list\n",
    "\timage = cv2.imread(imagePath)\n",
    "\t# image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\timage = img_to_array(image)\n",
    "\tdata.append(image)\n",
    "\t# extract the action and rate from the path and\n",
    "\t# update the respective lists\n",
    "\tsplit_path = imagePath.split(os.path.sep)\n",
    "\taction = split_path[-2]\n",
    "\tactionLabels.append(action)\n",
    "\tindex = int(split_path[-1].split(\"_\")[-1].split(\".\")[0])\n",
    "\tvalue_rate = rate_vectors.iloc[index].tolist()\n",
    "\trate_vector_value.append(value_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] data matrix: 5594 images (13.11MB)\n",
      "[INFO] binarizing labels...\n"
     ]
    }
   ],
   "source": [
    "# scale the raw pixel intensities to the range [0, 1] and convert to\n",
    "# a NumPy array\n",
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "print(\"[INFO] data matrix: {} images ({:.2f}MB)\".format(\n",
    "\tlen(data), data.nbytes / (1024 * 1000.0)))\n",
    "# convert the label lists to NumPy arrays prior to binarization\n",
    "actionLabels = np.array(actionLabels)\n",
    "rate_vector_value = np.array(rate_vector_value) / 7\n",
    "# binarize both sets of labels\n",
    "print(\"[INFO] binarizing labels...\")\n",
    "actionLB = LabelBinarizer()\n",
    "actionLabels = actionLB.fit_transform(actionLabels)\n",
    "\n",
    "# partition the data into training and testing splits using 80% of\n",
    "split = train_test_split(data, actionLabels, rate_vector_value, test_size=0.2, random_state=rs, shuffle=True)\n",
    "(trainX, testX, trainActionY, testActionY, trainRateY, testRateY) = split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTION_NUM = 5\n",
    "RATE_VECTOR_LEN = 5\n",
    "\n",
    "# Define model layers.\n",
    "input_layer = Input(shape=(IMG_SIZE,IMG_SIZE,3))\n",
    "X = Conv2D(8, 4, padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.001))(input_layer)\n",
    "X = Conv2D(16, 4, padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.001))(X)\n",
    "X = Conv2D(16, 3, padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.001))(X)\n",
    "X = MaxPooling2D()(X)\n",
    "X = Conv2D(8, 3, padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.001))(X)\n",
    "X = Dropout(0.5)(X)\n",
    "X = Flatten()(X)\n",
    "X = Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.001))(X)\n",
    "\n",
    "# action output will be fed from the first dense\n",
    "action_output = Dense(ACTION_NUM, activation='softmax', name='action_output')(X) #20\n",
    "rate_output = Dense(RATE_VECTOR_LEN, activation='linear', name='rate_output')(X)\n",
    "\n",
    "# final_action_output = Dense(ACTION_NUM, activation='softmax', name='action_output')(X)\n",
    "\n",
    "# Define the model with the input layer \n",
    "# and a list of output layers\n",
    "model = Model(inputs=input_layer,outputs=[action_output, rate_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 10, 10, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 10, 10, 8)    392         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 10, 10, 16)   2064        conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 10, 10, 16)   2320        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 5, 5, 16)     0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 5, 5, 8)      1160        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 5, 5, 8)      0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 200)          0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 32)           6432        flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "action_output (Dense)           (None, 5)            165         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "rate_output (Dense)             (None, 5)            165         dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 12,698\n",
      "Trainable params: 12,698\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    }
   ],
   "source": [
    "# initialize the number of epochs to train for, initial learning rate,\n",
    "# batch size, and image dimensions\n",
    "EPOCHS = 350\n",
    "INIT_LR = 1e-3\n",
    "\n",
    "# define two dictionaries: one that specifies the loss method for\n",
    "# each output of the network along with a second dictionary that\n",
    "# specifies the weight per loss\n",
    "\n",
    "# \t\"action_output\": tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "\n",
    "losses = {\n",
    "\t\"action_output\": \"categorical_crossentropy\",\n",
    "\t\"rate_output\": \"mse\"\n",
    "}\n",
    "lossWeights = {\"action_output\": 1.0, \"rate_output\": 0.0}\n",
    "\n",
    "# initialize the optimizer and compile the model\n",
    "print(\"[INFO] compiling model...\")\n",
    "\n",
    "opt = Adam(learning_rate=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(optimizer=opt, loss=losses, loss_weights=lossWeights,\n",
    "\tmetrics=[\"accuracy\"])\n",
    "\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss=losses,\n",
    "# \t\t\t  loss_weights=lossWeights,\n",
    "#               metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/350\n",
      "140/140 [==============================] - 3s 10ms/step - loss: 1.5067 - action_output_loss: 1.4343 - rate_output_loss: 0.6040 - action_output_accuracy: 0.3841 - rate_output_accuracy: 0.1940 - val_loss: 1.2962 - val_action_output_loss: 1.2302 - val_rate_output_loss: 0.5977 - val_action_output_accuracy: 0.4915 - val_rate_output_accuracy: 0.2082\n",
      "Epoch 2/350\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 1.2065 - action_output_loss: 1.1359 - rate_output_loss: 0.7961 - action_output_accuracy: 0.5343 - rate_output_accuracy: 0.1864 - val_loss: 1.0321 - val_action_output_loss: 0.9570 - val_rate_output_loss: 0.7103 - val_action_output_accuracy: 0.6604 - val_rate_output_accuracy: 0.2082\n",
      "Epoch 3/350\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 1.0299 - action_output_loss: 0.9503 - rate_output_loss: 1.0170 - action_output_accuracy: 0.6391 - rate_output_accuracy: 0.1810 - val_loss: 0.8327 - val_action_output_loss: 0.7493 - val_rate_output_loss: 1.1486 - val_action_output_accuracy: 0.7453 - val_rate_output_accuracy: 0.1841\n",
      "Epoch 4/350\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.8878 - action_output_loss: 0.8008 - rate_output_loss: 1.2184 - action_output_accuracy: 0.7128 - rate_output_accuracy: 0.1828 - val_loss: 0.7375 - val_action_output_loss: 0.6474 - val_rate_output_loss: 1.2832 - val_action_output_accuracy: 0.7703 - val_rate_output_accuracy: 0.1832\n",
      "Epoch 5/350\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.8237 - action_output_loss: 0.7318 - rate_output_loss: 1.2337 - action_output_accuracy: 0.7339 - rate_output_accuracy: 0.1823 - val_loss: 0.7013 - val_action_output_loss: 0.6076 - val_rate_output_loss: 1.2754 - val_action_output_accuracy: 0.7676 - val_rate_output_accuracy: 0.1787\n",
      "Epoch 6/350\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.7919 - action_output_loss: 0.6969 - rate_output_loss: 1.2272 - action_output_accuracy: 0.7470 - rate_output_accuracy: 0.1875 - val_loss: 0.6680 - val_action_output_loss: 0.5719 - val_rate_output_loss: 1.0504 - val_action_output_accuracy: 0.7909 - val_rate_output_accuracy: 0.1877\n",
      "Epoch 7/350\n",
      "129/140 [==========================>...] - ETA: 0s - loss: 0.7656 - action_output_loss: 0.6686 - rate_output_loss: 1.2016 - action_output_accuracy: 0.7636 - rate_output_accuracy: 0.1805"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2815247/812830129.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m history = model.fit(x=trainX, y={\"action_output\": trainActionY, \"rate_output\": trainRateY},\n\u001b[1;32m      3\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"action_output\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtestActionY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rate_output\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtestRateY\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \tepochs=EPOCHS)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train the network to perform multi-output\n",
    "history = model.fit(x=trainX, y={\"action_output\": trainActionY, \"rate_output\": trainRateY},\n",
    "\tvalidation_data=(testX, {\"action_output\": testActionY, \"rate_output\": testRateY}),\n",
    "\tepochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['action_output_accuracy']\n",
    "val_acc = history.history['val_action_output_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(EPOCHS)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.evaluate(x=testX, y={'action_output': testActionY, 'rate_output': testRateY})\n",
    "# \"coll_output\": testCollY, \"comp_output\": testCompY, \"pred_output\": testPredY, \"self_output\": testSelfY, \"wise_output\": testWiseY})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire model as a SavedModel.\n",
    "model.save('./data/'+map_dir+'/humanModel_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_model = tf.keras.models.load_model('./data/humanModel/mode_v0')\n",
    "\n",
    "# # Check its architecture\n",
    "# new_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./data/humanModel_v1_dataset/38/-Ms8av2Z5M2XEIGMqjsx_70.png\"\n",
    "\n",
    "img = keras.preprocessing.image.load_img(\n",
    "    path, target_size=(IMG_SIZE, IMG_SIZE)\n",
    ")\n",
    "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "img_array = img_array / 255.0\n",
    "predictions = model.predict(img_array)\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(np.argmax(predictions[0]), 100 * np.max(predictions[0]))\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad60775ae12af945b53c5c94c294ef05f229143b8585a0d23625a81e181fdccc"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('tf-gpu': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
