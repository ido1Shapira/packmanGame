{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# ! pip install split-folders\n",
    "import splitfolders\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rs = 42\n",
    "def reset_random_seeds(rs):\n",
    "   os.environ['PYTHONHASHSEED']=str(rs)\n",
    "   tf.random.set_seed(rs)\n",
    "   np.random.seed(rs)\n",
    "   random.seed(rs)\n",
    "reset_random_seeds(rs)\n",
    "\n",
    "map_dir = 'map 5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove prev saved database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database exists\n"
     ]
    }
   ],
   "source": [
    "dir_path = './data/humanModel_v1_dataset_split'\n",
    "if os.path.exists(dir_path):\n",
    "    # shutil.rmtree(dir_path)\n",
    "    print(\"Database exists\")\n",
    "else:\n",
    "    print(\"File not found in the directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into train , test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 1056 files [00:00, 13497.19 files/s]\n",
      "Copying files: 1056 files [00:00, 14296.46 files/s]\n"
     ]
    }
   ],
   "source": [
    "# train, test split\n",
    "splitfolders.ratio('./data/humanModel_v1_dataset/action_target', output=\"./data/humanModel_v1_dataset_split/action_target\", ratio=(0.8, 0.2))\n",
    "splitfolders.ratio('./data/humanModel_v1_dataset/rate_target', output=\"./data/humanModel_v1_dataset_split/rate_target\", ratio=(0.8, 0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 843 images belonging to 5 classes.\n",
      "Found 213 images belonging to 5 classes.\n",
      "Found 842 images belonging to 7 classes.\n",
      "Found 214 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "IMG_SIZE = 10\n",
    "\n",
    "datagen = ImageDataGenerator(rescale = 1./255)\n",
    "train = datagen.flow_from_directory('./data/humanModel_v1_dataset_split/action_target/train',\n",
    "                                            target_size = (IMG_SIZE,IMG_SIZE), batch_size = batch_size, seed=rs, class_mode='sparse')\n",
    "\n",
    "test = datagen.flow_from_directory('./data/humanModel_v1_dataset_split/action_target/val',\n",
    "                                            target_size = (IMG_SIZE, IMG_SIZE), batch_size = batch_size, seed=rs, class_mode='sparse')\n",
    "\n",
    "train = datagen.flow_from_directory('./data/humanModel_v1_dataset_split/rate_target/train',\n",
    "                                            target_size = (IMG_SIZE,IMG_SIZE), batch_size = batch_size, seed=rs, class_mode='sparse')\n",
    "\n",
    "test = datagen.flow_from_directory('./data/humanModel_v1_dataset_split/rate_target/val',\n",
    "                                            target_size = (IMG_SIZE, IMG_SIZE), batch_size = batch_size, seed=rs, class_mode='sparse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_classes = 5\n",
    "\n",
    "# model = Sequential([\n",
    "#   layers.Conv2D(8, 4, padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.001), input_shape=[IMG_SIZE,IMG_SIZE,3]),\n",
    "#   layers.Conv2D(16, 4, padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "#   layers.Conv2D(16, 3, padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "#   layers.MaxPooling2D(),\n",
    "#   layers.Conv2D(8, 3, padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "#   layers.Dropout(0.5),\n",
    "#   layers.Flatten(),\n",
    "#   layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "#   layers.Dense(num_classes, activation='softmax')\n",
    "# ])\n",
    "\n",
    "# Define model layers.\n",
    "input_layer = Input(shape=(IMG_SIZE,IMG_SIZE,3))\n",
    "X = Conv2D(8, 4, padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.001))(input_layer)\n",
    "X = Conv2D(16, 4, padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.001))(X)\n",
    "X = Conv2D(16, 3, padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.001))(X)\n",
    "X = MaxPooling2D()(X)\n",
    "X = Conv2D(8, 3, padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.001))(X)\n",
    "X = Dropout(0.5)(X)\n",
    "X = Flatten()(X)\n",
    "X = Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.001))(X)\n",
    "\n",
    "# action output will be fed from the first dense\n",
    "action_output = Dense(units='1', name='action_output')(X)\n",
    "# rate output will be fed from the second dense\n",
    "rate_output = Dense(units='1',name='rate_output')(X)\n",
    "\n",
    "# Define the model with the input layer \n",
    "# and a list of output layers\n",
    "model = Model(inputs=input_layer,outputs=[action_output, rate_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "            loss={'action_output': 'mse', 'rate_output': 'mse'},\n",
    "            #   loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            #   metrics=['accuracy'])\n",
    "            metrics={'action_output':tf.keras.metrics.RootMeanSquaredError(),\n",
    "                    'rate_output':tf.keras.metrics.RootMeanSquaredError()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 10, 10, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 10, 10, 8)    392         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 10, 10, 16)   2064        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 10, 10, 16)   2320        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 5, 5, 16)     0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 5, 5, 8)      1160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 5, 5, 8)      0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 200)          0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           6432        flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "action_output (Dense)           (None, 1)            33          dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "rate_output (Dense)             (None, 1)            33          dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 12,434\n",
      "Trainable params: 12,434\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-13 17:03:36.973598: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "/home/ido/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/keras/backend.py:4907: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  '\"`sparse_categorical_crossentropy` received `from_logits=True`, but '\n",
      "2022-03-13 17:03:37.602675: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 23ms/step - loss: nan - accuracy: 0.2827 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 2/200\n",
      "14/14 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 3/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 4/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 5/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 6/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 7/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 8/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 9/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 10/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 11/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 12/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 13/200\n",
      "14/14 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 14/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 15/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 16/200\n",
      "14/14 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 17/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 18/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 19/200\n",
      "14/14 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 20/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 21/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 22/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 23/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 24/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 25/200\n",
      "14/14 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 26/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 27/200\n",
      "14/14 [==============================] - 0s 16ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 28/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 29/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 30/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 31/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 32/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 33/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 34/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 35/200\n",
      "14/14 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 36/200\n",
      "14/14 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 37/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 38/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 39/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 40/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 41/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 42/200\n",
      "14/14 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 43/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 44/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 45/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 46/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 47/200\n",
      "14/14 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 48/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 49/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 50/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 51/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 52/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 53/200\n",
      "14/14 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 54/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 55/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 56/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 57/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 58/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 59/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 60/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 61/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 62/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 63/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 64/200\n",
      "14/14 [==============================] - 0s 15ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 65/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 66/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 67/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 68/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 69/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 70/200\n",
      "14/14 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 71/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 72/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 73/200\n",
      "14/14 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 74/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 75/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 76/200\n",
      "14/14 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 77/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 78/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 79/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 80/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 81/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 82/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 83/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 84/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 85/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 86/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 87/200\n",
      "14/14 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 88/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 89/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 90/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 91/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 92/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 93/200\n",
      "14/14 [==============================] - 0s 15ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 94/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 95/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 96/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 97/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 98/200\n",
      "14/14 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 99/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 100/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 101/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 102/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 103/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 104/200\n",
      "14/14 [==============================] - 0s 15ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 105/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 106/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 107/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 108/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 109/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 110/200\n",
      "14/14 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 111/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 112/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 113/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 114/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 115/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 116/200\n",
      "14/14 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 117/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 118/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 119/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 120/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 121/200\n",
      "14/14 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 122/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 123/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 124/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 125/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 126/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 127/200\n",
      "14/14 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 128/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 129/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 130/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 131/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 132/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 133/200\n",
      "14/14 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 134/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 135/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 136/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 137/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 138/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 139/200\n",
      "14/14 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 140/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 141/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 142/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 143/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 144/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 145/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 146/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 147/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 148/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 149/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 150/200\n",
      "14/14 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 151/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 152/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 153/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 154/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 155/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 156/200\n",
      "14/14 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 157/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 158/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 159/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 160/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 161/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 162/200\n",
      "14/14 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 163/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 164/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 165/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 166/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 167/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 168/200\n",
      "14/14 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 169/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 170/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 171/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 172/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 173/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 174/200\n",
      "14/14 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 175/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 176/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 177/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 178/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 179/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 180/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 181/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 182/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 183/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 184/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 185/200\n",
      "14/14 [==============================] - 0s 15ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 186/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 187/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 188/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 189/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 190/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 191/200\n",
      "14/14 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 192/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 193/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 194/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 195/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 196/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 197/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 198/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 199/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n",
      "Epoch 200/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.2874 - val_loss: nan - val_accuracy: 0.2850\n"
     ]
    }
   ],
   "source": [
    "epochs=200\n",
    "history = model.fit(\n",
    "  train,\n",
    "  validation_data=test,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.2850\n",
      "Test accuracy : 0.2850467264652252\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test)\n",
    "print('Test accuracy :', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire model as a SavedModel.\n",
    "# model.save('./data/humanModel/mode_v0')\n",
    "model.save('./data/'+map_dir+'/humanModel_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model in js format\n",
    "# import tensorflowjs as tfjs\n",
    "# tfjs.converters.save_keras_model(model, 'data/humanModel/js_model_v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_model = tf.keras.models.load_model('./data/humanModel/mode_v0')\n",
    "\n",
    "# # Check its architecture\n",
    "# new_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/humanModel_v1_dataset_split/val/32_1/-Ms8jLrHMPiQF4tLfvKR_15.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_82420/1946729614.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m img = keras.preprocessing.image.load_img(\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m \u001b[0mimg_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    312\u001b[0m   \"\"\"\n\u001b[1;32m    313\u001b[0m   return image.load_img(path, grayscale=grayscale, color_mode=color_mode,\n\u001b[0;32m--> 314\u001b[0;31m                         target_size=target_size, interpolation=interpolation)\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    111\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    112\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/humanModel_v1_dataset_split/val/32_1/-Ms8jLrHMPiQF4tLfvKR_15.png'"
     ]
    }
   ],
   "source": [
    "path = \"./data/humanModel_v1_dataset_split/val/32_1/-Ms8jLrHMPiQF4tLfvKR_15.png\"\n",
    "\n",
    "img = keras.preprocessing.image.load_img(\n",
    "    path, target_size=(IMG_SIZE, IMG_SIZE)\n",
    ")\n",
    "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "img_array = img_array/255\n",
    "predictions = model.predict(img_array)[0]\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(np.argmax(predictions), 100 * np.max(predictions))\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad60775ae12af945b53c5c94c294ef05f229143b8585a0d23625a81e181fdccc"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('tf-gpu': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
